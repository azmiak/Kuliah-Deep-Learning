{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 16: Natural Language Processing with RNNs and Attention\n",
        "\n",
        "**Tujuan:** Menguasai pemrosesan teks sekuens: character RNN, word embeddings, encoder–decoder, dan mekanisme attention (Transformer).\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Character-Level RNN (Shakespeare Text)\n",
        "\n",
        "- **Dataset:** teks Shakespeare  \n",
        "- **Tokenisasi:** character-level  \n",
        "- **Model:** Embedding → SimpleRNN/LSTM → Dense(softmax)  \n",
        "- **Training:** prediksi karakter berikutnya  \n",
        "- **Sampling:** generate teks baru"
      ],
      "metadata": {
        "id": "Fa_sNq5lmJkn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MkcAHa6JmI2M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Muat data (misal 'shakespeare.txt')"
      ],
      "metadata": {
        "id": "WS4YwaDPmirr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('shakespeare.txt', 'r').read().lower()\n",
        "chars = sorted(set(text))\n",
        "char2idx = {c:i for i,c in enumerate(chars)}\n",
        "idx2char = np.array(chars)"
      ],
      "metadata": {
        "id": "elzlcIxZmjYZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Encode teks ke integer"
      ],
      "metadata": {
        "id": "DvTpFnhLmq5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "BjWI054pmu71"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Windowing: input seq length N, target = next char"
      ],
      "metadata": {
        "id": "A9o9KPwCmzlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    return chunk[:-1], chunk[1:]\n",
        "\n",
        "dataset = sequences.map(split_input_target).shuffle(10000).batch(64, drop_remainder=True)"
      ],
      "metadata": {
        "id": "iylBS59Rm4Po"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Bangun model"
      ],
      "metadata": {
        "id": "kPaCoF5Vm6PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "embedding_dim = 256\n",
        "rnn_units = 512\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim),\n",
        "    layers.LSTM(rnn_units, return_sequences=True, stateful=False),\n",
        "    layers.Dense(vocab_size)\n",
        "])"
      ],
      "metadata": {
        "id": "fg0nPgEDm-cQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Compile & train (demo singkat)"
      ],
      "metadata": {
        "id": "kKL3Ida_m_4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer='adam')\n",
        "\n",
        "model.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXBmGd5Dmdje",
        "outputId": "dbe7178c-4ac6-4704-f4b7-d5de079fceef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 3.4457\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.0955 \n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.1611 \n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.1099\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0211\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9431 \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9317 \n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.9085 \n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.8712\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.8338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799678192fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Sentiment Analysis (IMDB) dengan Embeddings + LSTM\n",
        "- Dataset: `tf.keras.datasets.imdb`\n",
        "\n",
        "- Preprocessing: `TextVectorization` → integer tokens\n",
        "\n",
        "- Model: Embedding → LSTM → Dense(sigmoid)\n",
        "\n",
        "- Loss: binary crossentropy"
      ],
      "metadata": {
        "id": "9EIIuq_7nt1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "MVvxCZC4n3MX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Load data (top 10k words)"
      ],
      "metadata": {
        "id": "23O7U1PGn_yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "word_index = imdb.get_word_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W84DIO1IoCUU",
        "outputId": "180c153e-e5aa-4b8c-e2ce-aa569cb22f26"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Decode & gunakan TextVectorization"
      ],
      "metadata": {
        "id": "lYAd-x_loElc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = {i+3:w for w,i in word_index.items()}\n",
        "idx2word[0],idx2word[1],idx2word[2] = '<pad>','<start>','<unk>'\n",
        "def decode_review(ids): return ' '.join(idx2word.get(i,'?') for i in ids)\n",
        "\n",
        "# Direct use dataset of integers\n",
        "max_len = 200\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test  = tf.keras.preprocessing.sequence.pad_sequences(X_test,  maxlen=max_len)"
      ],
      "metadata": {
        "id": "zUzwlKvBoRbQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Bangun model"
      ],
      "metadata": {
        "id": "0YGJ805goSVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.Sequential([\n",
        "    layers.Embedding(10000, 16, input_length=max_len),\n",
        "    layers.Bidirectional(layers.LSTM(64)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "FwbOuoJXoVYh",
        "outputId": "5fae6233-4340-4908-fefe-4237905d23ae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Latih (demo singkat)"
      ],
      "metadata": {
        "id": "oBcpKRYnodK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2jmEB5nonNF",
        "outputId": "6e5c4865-61cf-473e-ed0b-b47a099a572b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8801 - loss: 0.2985 - val_accuracy: 0.8734 - val_loss: 0.3031\n",
            "Epoch 2/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9222 - loss: 0.2071 - val_accuracy: 0.8780 - val_loss: 0.3022\n",
            "Epoch 3/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9476 - loss: 0.1518 - val_accuracy: 0.8670 - val_loss: 0.3173\n",
            "Epoch 4/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9603 - loss: 0.1242 - val_accuracy: 0.8708 - val_loss: 0.3941\n",
            "Epoch 5/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9686 - loss: 0.0976 - val_accuracy: 0.8712 - val_loss: 0.3857\n",
            "Epoch 6/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9738 - loss: 0.0814 - val_accuracy: 0.8666 - val_loss: 0.4061\n",
            "Epoch 7/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9770 - loss: 0.0730 - val_accuracy: 0.8586 - val_loss: 0.5456\n",
            "Epoch 8/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.9809 - loss: 0.0611 - val_accuracy: 0.8618 - val_loss: 0.4733\n",
            "Epoch 9/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9870 - loss: 0.0470 - val_accuracy: 0.8622 - val_loss: 0.5278\n",
            "Epoch 10/10\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0549 - val_accuracy: 0.8644 - val_loss: 0.5962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Encoder–Decoder untuk Machine Translation\n",
        "- Dataset: sepasang kalimat (EN→FR)\n",
        "\n",
        "- Model:\n",
        "\n",
        "  - Encoder: Embedding→LSTM → state\n",
        "\n",
        "  - Decoder: Embedding→LSTM (init state encoder) → Dense(softmax)\n",
        "\n",
        "- Training: teacher forcing"
      ],
      "metadata": {
        "id": "3Pa6gbbnopa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Contoh mock dataset"
      ],
      "metadata": {
        "id": "bsy92qfRo0Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_sentences = ['hello', 'how are you', 'good morning']\n",
        "fra_sentences = ['bonjour', 'comment ça va', 'bonjour']"
      ],
      "metadata": {
        "id": "cWig3PceoyXi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Tokenisasi & padding"
      ],
      "metadata": {
        "id": "iQOb8D6io4K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_en = TextVectorization(output_mode='int', output_sequence_length=5)\n",
        "vectorizer_en.adapt(eng_sentences)\n",
        "vectorizer_fr = TextVectorization(output_mode='int', output_sequence_length=5)\n",
        "vectorizer_fr.adapt(fra_sentences)\n",
        "\n",
        "X_en = vectorizer_en(eng_sentences)\n",
        "X_fr = vectorizer_fr(fra_sentences)"
      ],
      "metadata": {
        "id": "BZAoQgyJo6YM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Bangun encoder–decoder"
      ],
      "metadata": {
        "id": "yu6hMrq_o9Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "enc_emb = layers.Embedding(input_dim=vectorizer_en.vocabulary_size(), output_dim=16)\n",
        "dec_emb = layers.Embedding(input_dim=vectorizer_fr.vocabulary_size(), output_dim=16)\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,))\n",
        "enc_x = enc_emb(encoder_inputs)\n",
        "_, state_h, state_c = layers.LSTM(32, return_state=True)(enc_x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,))\n",
        "dec_x = dec_emb(decoder_inputs)\n",
        "dec_lstm = layers.LSTM(32, return_sequences=True, return_state=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_x, initial_state=[state_h, state_c])\n",
        "decoder_dense = layers.Dense(vectorizer_fr.vocabulary_size(), activation='softmax')\n",
        "decoder_outputs = decoder_dense(dec_outputs)\n",
        "\n",
        "seq2seq = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "seq2seq.summary()\n",
        "seq2seq.fit([X_en, X_fr[:,:-1]], X_fr[:,1:,None], epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "rJyw5cwJpASd",
        "outputId": "a48f1b6b-6cab-424e-de63-11a075bdce97"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │        \u001b[38;5;34m128\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m96\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),      │      \u001b[38;5;34m6,272\u001b[0m │ embedding_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),       │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │      \u001b[38;5;34m6,272\u001b[0m │ embedding_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),  │            │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)   │        \u001b[38;5;34m198\u001b[0m │ lstm_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │ embedding_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),       │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │ embedding_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),  │            │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ lstm_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,966\u001b[0m (50.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,966</span> (50.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,966\u001b[0m (50.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,966</span> (50.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 1.7939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7996ba34c110>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Attention & Transformer (Sekilas)\n",
        "- Attention: bobot kontribusi setiap encoding langkah\n",
        "\n",
        "- Transformer: layer multi-head attention + feed‑forward tanpa RNN"
      ],
      "metadata": {
        "id": "kfQelIVOpIss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention"
      ],
      "metadata": {
        "id": "BJo1t29fpPDf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Contoh single-head attention"
      ],
      "metadata": {
        "id": "mLmIfGnPpQM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data\n",
        "query = tf.random.normal((1, 5, 16))\n",
        "key   = tf.random.normal((1, 6, 16))\n",
        "val   = tf.random.normal((1, 6, 16))\n",
        "\n",
        "attn_layer = MultiHeadAttention(num_heads=2, key_dim=16)\n",
        "output, weights = attn_layer(\n",
        "    query=query,\n",
        "    value=val,\n",
        "    key=key,\n",
        "    return_attention_scores=True\n",
        ")\n",
        "\n",
        "print(\"Attention output shape:\", output.shape)\n",
        "print(\"Attention scores shape:\", weights.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P18BNWWqpT0E",
        "outputId": "ce53d8b6-3914-4e2c-cfd5-e59ee7908a8f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention output shape: (1, 5, 16)\n",
            "Attention scores shape: (1, 2, 5, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ringkasan Chapter 16\n",
        "1. Char-RNN untuk generate teks character-level.\n",
        "\n",
        "2. Embeddings+LSTM efektif untuk sentiment analysis.\n",
        "\n",
        "3. Encoder–Decoder (seq2seq) dasar neural machine translation.\n",
        "\n",
        "4. Attention meningkatkan konteks global; pondasi Transformer."
      ],
      "metadata": {
        "id": "-Kw_NxZ6pVl1"
      }
    }
  ]
}