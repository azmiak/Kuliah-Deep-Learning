{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7: Ensemble Learning and Random Forests\n",
        "\n",
        "**Tujuan:** Memahami teknik ensemble—Voting, Bagging/Pasting, Random Patches/Subspaces, Random Forests, Extra‑Trees, Boosting (AdaBoost & Gradient Boosting), dan Stacking.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Voting Classifier\n",
        "\n",
        "- **Ide:** Gabungkan beberapa model (“weak learners”) dengan voting:  \n",
        "  - **Hard voting** → mayoritas label  \n",
        "  - **Soft voting** → rata‑rata probabilitas  \n",
        "- Berguna untuk meningkatkan stabilitas dan akurasi dengan model beragam."
      ],
      "metadata": {
        "id": "F4IikEigJ3Fy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqJ4fcu5Jazc",
        "outputId": "f1c21785-6c7a-44cc-b455-c0e187badcfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting (hard) Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Persiapkan data Iris\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, random_state=42\n",
        ")\n",
        "\n",
        "# Definisikan base learners\n",
        "clf1 = LogisticRegression(max_iter=200)\n",
        "clf2 = SVC(kernel='rbf', probability=True)\n",
        "clf3 = LogisticRegression(C=0.5, max_iter=200)\n",
        "\n",
        "# Hard Voting\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr1',clf1),('svc',clf2),('lr2',clf3)],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "print(\"Voting (hard) Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Bagging & Pasting\n",
        "- Bagging (Bootstrap AGGregating): sampling dengan pengembalian → tiap learner latih subset data berbeda\n",
        "\n",
        "- Pasting: sampling tanpa pengembalian\n",
        "\n",
        "- Mengurangi varians, cocok untuk model high‑variance (Decision Trees)."
      ],
      "metadata": {
        "id": "GmmsOZnhKGRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, random_state=42\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bag_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvzECv1wKTIt",
        "outputId": "12b7fd37-7214-41c1-f5fc-e83d9b7893d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Random Patches & Random Subspaces\n",
        "- Random Subspaces: sample subset fitur untuk tiap learner\n",
        "\n",
        "- Random Patches: sample subset data + subset fitur\n",
        "\n",
        "- Cara mengurangi korelasi antar model tambahan."
      ],
      "metadata": {
        "id": "FbQKR4jsKZQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh Random Patches: bootstrap + max_features\n",
        "patches_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=200,\n",
        "    max_samples=100, max_features=2,\n",
        "    bootstrap=True, bootstrap_features=True,\n",
        "    random_state=42\n",
        ")\n",
        "patches_clf.fit(X_train, y_train)\n",
        "print(\"Random Patches Accuracy:\", accuracy_score(y_test, patches_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdpjCiskKh4E",
        "outputId": "9247e0f6-04c8-4df7-d4f3-ad133b855919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Patches Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Random Forest\n",
        "- Random Forest = Bagging pada Decision Trees + random feature selection di tiap split\n",
        "\n",
        "- Parameter utama: `_estimators`, `max_features`, `max_depth`."
      ],
      "metadata": {
        "id": "pu5Bz8YRKlv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(\n",
        "    n_estimators=500, max_features='sqrt', random_state=42\n",
        ")\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rnd_clf.predict(X_test)))\n",
        "\n",
        "# Feature importance\n",
        "import pandas as pd\n",
        "feat_imp = pd.Series(rnd_clf.feature_importances_, index=iris.feature_names)\n",
        "feat_imp.sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "xvSUfNqtK0O2",
        "outputId": "75584ff4-9319-4e5a-ea94-e66e03062cc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "petal length (cm)    0.447097\n",
              "petal width (cm)     0.405924\n",
              "sepal length (cm)    0.113184\n",
              "sepal width (cm)     0.033795\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>petal length (cm)</th>\n",
              "      <td>0.447097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>petal width (cm)</th>\n",
              "      <td>0.405924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <td>0.113184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <td>0.033795</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Extra‑Trees (Extremely Randomized Trees)\n",
        "- Mirip Random Forest, tapi randomisasi lebih agresif:\n",
        "\n",
        "  - Split points dipilih acak\n",
        "\n",
        "- Bias sedikit naik, varian turun, biasanya lebih cepat."
      ],
      "metadata": {
        "id": "O05qpfVdK0dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et_clf = ExtraTreesClassifier(\n",
        "    n_estimators=500, max_features='sqrt', random_state=42\n",
        ")\n",
        "et_clf.fit(X_train, y_train)\n",
        "print(\"Extra-Trees Accuracy:\", accuracy_score(y_test, et_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayw5sdMeK7e5",
        "outputId": "7862f488-b96c-4bcb-9c99-8f53f20ec40d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extra-Trees Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Boosting\n",
        "###A. AdaBoost (Adaptive Boosting)\n",
        "- Berikan bobot lebih besar pada misclassified instances\n",
        "\n",
        "- Weak learner: Decision Stump (Tree depth=1)"
      ],
      "metadata": {
        "id": "i-I0P7z4YLcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier # Import DecisionTreeClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200, algorithm=\"SAMME\", random_state=42\n",
        ")\n",
        "ada_clf.fit(X_train, y_train)\n",
        "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, ada_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5rSsWq6YSsN",
        "outputId": "bd3b2e9d-dd55-4bd2-bb46-9aa3f5f1135b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Gradient Boosting\n",
        "- Sequential build trees yang memperbaiki residual (gradient of loss)\n",
        "\n",
        "- Parameter: `learning_rate`, `n_estimators`, `max_depth`"
      ],
      "metadata": {
        "id": "9txoSY2ZYcLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(\n",
        "    n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42\n",
        ")\n",
        "gb_clf.fit(X_train, y_train)\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OIq4KCgY7YK",
        "outputId": "644f117b-24c7-47a4-eece-627f1d03c61a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Stacking\n",
        "- Combine predictions dari beberapa model level‑0 sebagai fitur untuk level‑1 learner\n",
        "\n",
        "- Meningkatkan akurasi dengan meta‑learner."
      ],
      "metadata": {
        "id": "w9I5n9AdY9U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rnd_clf),\n",
        "        ('gb', gb_clf),\n",
        "        ('knn', KNeighborsClassifier())\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "stack_clf.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, stack_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NURG2CwsZBOz",
        "outputId": "cbb53801-2f7e-42ea-f2dc-0b6899a1e6d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ringkasan Chapter 7\n",
        "- Voting menggabungkan model dengan voting.\n",
        "\n",
        "- Bagging/Pasting kurangi varians.\n",
        "\n",
        "- Random Forest & Extra-Trees: ensemble Decision Trees.\n",
        "\n",
        "- Boosting (AdaBoost & Gradient Boosting) kurangi bias & varians.\n",
        "\n",
        "- Stacking: meta‑learner atas prediksi model lain."
      ],
      "metadata": {
        "id": "n_WtU85NZDiS"
      }
    }
  ]
}